{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check calculation_system_relax records\n",
    "\n",
    "This Notebook is designed for investigating results in calculation_system_relax records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "from __future__ import print_function\n",
    "import glob\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# pandas.pydata.org\n",
    "import pandas as pd\n",
    "\n",
    "# http://www.numpy.org/\n",
    "import numpy as np\n",
    "\n",
    "# https://github.com/usnistgov/DataModelDict\n",
    "from DataModelDict import DataModelDict as DM\n",
    "\n",
    "# https://github.com/usnistgov/atomman\n",
    "import atomman as am\n",
    "import atomman.unitconvert as uc\n",
    "\n",
    "# https://github.com/usnistgov/iprPy\n",
    "import iprPy\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plotting library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bokeh version = 0.12.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"5b4289a8-aeb5-4d56-b57d-45c915daee38\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"5b4289a8-aeb5-4d56-b57d-45c915daee38\");\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"5b4289a8-aeb5-4d56-b57d-45c915daee38\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '5b4289a8-aeb5-4d56-b57d-45c915daee38' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.7.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"5b4289a8-aeb5-4d56-b57d-45c915daee38\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.7.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.7.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"5b4289a8-aeb5-4d56-b57d-45c915daee38\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://bokeh.pydata.org/\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.embed import components\n",
    "from bokeh.resources import Resources, CDN\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import Range1d\n",
    "print('bokeh version =', bokeh.__version__)\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Read Calculation Data\n",
    "\n",
    "This section reads in raw data from a database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Raw Data\n",
    "\n",
    "This section reads in or generates the raw_data associated with the calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.1 Initialize database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- __dbasename__ is used here to predefine different dbase settings\n",
    "- __dbase__ is the iprPy.Database object to use for accessing a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dbasename = 'test2'\n",
    "\n",
    "# 'local' is a local directory\n",
    "if   dbasename == 'local':\n",
    "    dbase = iprPy.Database('local',   host='C:\\Users\\lmh1\\Documents\\calculations\\ipr\\library')\n",
    "\n",
    "# 'test' is a local directory for testing \n",
    "elif dbasename == 'test':\n",
    "    dbase = iprPy.Database('local',   host='C:\\Users\\lmh1\\Documents\\calculations\\ipr\\library_test')\n",
    "\n",
    "# 'test2' is a local directory for testing \n",
    "elif dbasename == 'test2':\n",
    "    dbase = iprPy.Database('local',   host='C:\\\\Users\\\\lmh1\\\\Documents\\\\calculations\\\\ipr\\\\test2')\n",
    "    \n",
    "# 'curator' is a local MDCS curator\n",
    "elif dbasename == 'curator':\n",
    "    dbase = iprPy.Database('curator', host='http://127.0.0.1:8000/', \n",
    "                                      user='admin', \n",
    "                                      pswd='admin')\n",
    "\n",
    "# 'iprhub' is the remote MDCS curator at iprhub\n",
    "elif dbasename == 'iprhub':\n",
    "    dbase = iprPy.Database('curator', host='https://iprhub.nist.gov/', \n",
    "                                      user='lmh1',\n",
    "                                      pswd='C:/users/lmh1/documents/iprhub/iprhub_password.txt',\n",
    "                                      cert='C:/users/lmh1/documents/iprhub/iprhub-ca.pem')\n",
    "else:\n",
    "    raise ValueError('unknown dbasename ' + dbasename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.2 Access records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 prototype records loaded\n"
     ]
    }
   ],
   "source": [
    "proto_df = dbase.get_records_df(style='crystal_prototype')\n",
    "print(str(len(proto_df)) + ' prototype records loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 potential records loaded\n"
     ]
    }
   ],
   "source": [
    "pot_df = dbase.get_records_df(style='potential_LAMMPS')\n",
    "print(str(len(pot_df)) + ' potential records loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lmh1\\documents\\python-packages\\atomman\\atomman\\core\\ElasticConstants.py:93: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  value[np.isclose(value/value.max(), 0.0, atol=1e-9)] = 0.0\n",
      "c:\\users\\lmh1\\documents\\python-packages\\atomman\\atomman\\core\\ElasticConstants.py:93: RuntimeWarning: invalid value encountered in true_divide\n",
      "  value[np.isclose(value/value.max(), 0.0, atol=1e-9)] = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 calculation records loaded\n"
     ]
    }
   ],
   "source": [
    "raw_df = dbase.get_records_df(style='calculation_system_relax')\n",
    "print(str(len(raw_df)) + ' calculation records loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.3 Check errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 450, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 58, in main\r\n",
      "    pressure_unit = input_dict['pressure_unit'])\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 170, in lammps_ELASTIC_refine\r\n",
      "    dmax=dmax, pressure_unit=pressure_unit)\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 333, in lammps_ELASTIC\r\n",
      "    output = lmp.run(lammps_command, 'in.elastic', mpi_command)\r\n",
      "  File \"c:\\users\\lmh1\\documents\\python-packages\\atomman\\atomman\\lammps\r",
      "un.py\", line 98, in run\r\n",
      "    raise ValueError('Invalid LAMMPS input: \n",
      "%s' % lines[-2])\r\n",
      "ValueError: Invalid LAMMPS input: \r\n",
      "Last command: read_restart restart.equil\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 450, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 58, in main\r\n",
      "    pressure_unit = input_dict['pressure_unit'])\r\n",
      "  File \"calc_LAMMPS_ELASTIC.py\", line 218, in lammps_ELASTIC_refine\r\n",
      "    raise RuntimeError('Failed to converge after 100 cycles')\r\n",
      "RuntimeError: Failed to converge after 100 cycles\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 158, in quick_a_Cij\r\n",
      "    strainrange=strainrange, cycle=cycle)\r\n",
      "  File \"calc_refine_structure.py\", line 349, in calc_cij\r\n",
      "    S = C.Sij\r\n",
      "  File \"c:\\users\\lmh1\\documents\\python-packages\\atomman\\atomman\\core\\ElasticConstants.py\", line 104, in Sij\r\n",
      "    return np.linalg.inv(self.Cij)\r\n",
      "  File \"C:\\Users\\lmh1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\n",
      "umpy\\linalg\\linalg.py\", line 526, in inv\r\n",
      "    ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj)\r\n",
      "  File \"C:\\Users\\lmh1\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\n",
      "umpy\\linalg\\linalg.py\", line 90, in _raise_linalgerror_singular\r\n",
      "    raise LinAlgError(\"Singular matrix\")\r\n",
      "numpy.linalg.linalg.LinAlgError: Singular matrix\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 158, in quick_a_Cij\r\n",
      "    strainrange=strainrange, cycle=cycle)\r\n",
      "  File \"calc_refine_structure.py\", line 365, in calc_cij\r\n",
      "    raise RuntimeError('Divergence of box dimensions to <= 0')\r\n",
      "RuntimeError: Divergence of box dimensions to <= 0\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 189, in quick_a_Cij\r\n",
      "    raise RuntimeError('Divergence of box dimensions')\r\n",
      "RuntimeError: Divergence of box dimensions\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 195, in quick_a_Cij\r\n",
      "    raise RuntimeError('Divergence of box dimensions')\r\n",
      "RuntimeError: Divergence of box dimensions\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 197, in quick_a_Cij\r\n",
      "    raise RuntimeError('Divergence of box dimensions')\r\n",
      "RuntimeError: Divergence of box dimensions\r\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\r\n",
      "  File \"calc_refine_structure.py\", line 444, in <module>\r\n",
      "    main(*sys.argv[1:])\r\n",
      "  File \"calc_refine_structure.py\", line 52, in main\r\n",
      "    strainrange = input_dict['strainrange'])\r\n",
      "  File \"calc_refine_structure.py\", line 219, in quick_a_Cij\r\n",
      "    raise RuntimeError('Failed to converge after 100 cycles')\r\n",
      "RuntimeError: Failed to converge after 100 cycles\r\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 'error' in raw_df:\n",
    "    for error in np.unique(raw_df[pd.notnull(raw_df.error)].error):\n",
    "        print(error)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Process Data\n",
    "\n",
    "This section processes and refines the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Identify composition\n",
    "\n",
    "We need to identify the composition of each calculation so that we can collect duplicates and filter out artificial compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- __counts__ is a dictionary counting the number of times each atype appears in a crystal prototype's unit cell (i.e. the number of symmetry equivalent sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for i, prototype in proto_df.iterrows():\n",
    "    model = DM(dbase.get_record(name=prototype.id, style='crystal_prototype').content)\n",
    "    counts[prototype.id] = np.unique(model.finds('component'), return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- __comp_refine()__ takes a list of symbols and count of how many times each symbol appears in a structure and generates a composition string.__comp_refine__ takes a list of symbols and count of how many times each symbol appears in a structure and generates a composition string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def comp_refine(symbols, counts):\n",
    "    \"\"\"Takes a list of symbols and count of how many times each symbol appears and generates a composition string.\"\"\"\n",
    "    primes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47]\n",
    "    \n",
    "    sym_dict = {}\n",
    "    for i in xrange(len(symbols)):\n",
    "        sym_dict[symbols[i]] = counts[i]\n",
    "    \n",
    "    for prime in primes:\n",
    "        if max(sym_dict.values()) < prime:\n",
    "            break\n",
    "        \n",
    "        while True:\n",
    "            breaktime = False\n",
    "            for value in sym_dict.values():\n",
    "                if value % prime != 0:\n",
    "                    breaktime = True\n",
    "                    break\n",
    "            if breaktime:\n",
    "                break\n",
    "            for key in sym_dict:\n",
    "                sym_dict[key] /= prime\n",
    "    \n",
    "    composition=''\n",
    "    for key in sorted(sym_dict):\n",
    "        if sym_dict[key] > 0:\n",
    "            composition += key\n",
    "            if sym_dict[key] != 1:\n",
    "                composition += str(sym_dict[key])\n",
    "            \n",
    "    return composition       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "compositions = []\n",
    "for i, calc in raw_df.iterrows():\n",
    "    compositions.append(comp_refine(calc.symbols, counts[calc.family]))\n",
    "raw_df = raw_df.assign(composition=compositions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Identify current ipr potentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract versionstyle and versionnumber from potential implementation ids\n",
    "versionstyle = []\n",
    "versionnumber = []\n",
    "for name in pot_df['id'].values:\n",
    "    version = name.split('--')[-1]\n",
    "    try:\n",
    "        versionnumber.append(int(version[-1]))\n",
    "    except:\n",
    "        versionnumber.append(np.nan)\n",
    "        versionstyle.append(version)\n",
    "    else:\n",
    "        versionstyle.append(version[:-1])\n",
    "\n",
    "pot_df['versionstyle'] = versionstyle\n",
    "pot_df['versionnumber'] = versionnumber\n",
    "\n",
    "# Loop through unique potential id's\n",
    "includeid = []\n",
    "for pot_id in np.unique(pot_df.pot_id.values):\n",
    "    check_df = pot_df[pot_df.pot_id == pot_id]\n",
    "    check_df = check_df[check_df.versionstyle == 'ipr']\n",
    "    check_df = check_df[check_df.versionnumber == check_df.versionnumber.max()]\n",
    "    if len(check_df) == 1:\n",
    "        includeid.append(check_df['id'].values[0])\n",
    "    elif len(check_df) > 1:\n",
    "        raise ValueError('Bad currentIPR check for '+pot_id)\n",
    "\n",
    "# Identify current IPR potentials\n",
    "raw_df['currentIPR'] = raw_df.potential_LAMMPS_id.isin(includeid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3 Identify crystals that have relaxed to a different crystal family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tol = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cubic', 'hexagonal', 'tetragonal'], \n",
       "      dtype='|S10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crystal_families = {}\n",
    "for proto_id, crystal_family in zip(proto_df['id'], proto_df.crystal_family):\n",
    "    crystal_families[proto_id] = crystal_family\n",
    "    \n",
    "crystal_families = {\n",
    "    #elemental\n",
    "    'A1--Cu--fcc':                'cubic',\n",
    "    'A2--W--bcc':                 'cubic',\n",
    "    'A3--Mg--hcp':                'hexagonal',\n",
    "    'A3\\'--alpha-La--double-hcp': 'hexagonal',\n",
    "    'A4--C--dc':                  'cubic',\n",
    "    'A5--beta-Sn':                'tetragonal',\n",
    "    'A6--In--bct':                'tetragonal',\n",
    "    'A7--alpha-As':               'hexagonal',\n",
    "    'A15--beta-W':                'cubic',\n",
    "    'Ah--alpha-Po--sc':           'cubic',\n",
    "   #1:1\n",
    "    'B1--NaCl--rock-salt':        'cubic',\n",
    "    'B2--CsCl':                   'cubic',\n",
    "    'B3--ZnS--cubic-zinc-blende': 'cubic',\n",
    "    'L1_0--AuCu':                 'tetragonal',\n",
    "   #1:2\n",
    "    'C1--CaF2--fluorite':         'cubic',\n",
    "   #1:3\n",
    "    'A15--Cr3Si':                 'cubic',\n",
    "    'D0_3--BiF3':                 'cubic',\n",
    "    'L1_2--AuCu3':                'cubic',\n",
    "   #1:1:2\n",
    "    'L2_1--AlCu2Mn--heusler':     'cubic'\n",
    "}\n",
    "np.unique(crystal_families.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hasrelaxed = np.empty(len(raw_df), dtype=bool)\n",
    "for i, row in enumerate(raw_df.itertuples()):\n",
    "    \n",
    "    # Extract data for comparison\n",
    "    a = row.final_a\n",
    "    b = row.final_b\n",
    "    c = row.final_c\n",
    "    family = row.family\n",
    "    crystal_family = crystal_families[family]\n",
    "    \n",
    "    # Evaluate based on crystal_family\n",
    "    if crystal_family == 'cubic':\n",
    "        if np.isclose(b/a, 1.0, atol=tol, rtol=0.0) and np.isclose(c/a, 1.0, atol=tol, rtol=0.0):\n",
    "            hasrelaxed[i] = False\n",
    "        else:\n",
    "            hasrelaxed[i] = True\n",
    " \n",
    "    elif crystal_family == 'hexagonal':\n",
    "        if np.isclose(b/a, 3.**0.5, atol=tol, rtol=0.0):\n",
    "            hasrelaxed[i] = False\n",
    "        else:\n",
    "            hasrelaxed[i] = True\n",
    "            \n",
    "    elif crystal_family == 'tetragonal':\n",
    "        if np.isclose(b/a, 1.0, atol=tol, rtol=0.0) and not np.isclose(c/a, 1.0, atol=tol, rtol=0.0):\n",
    "            hasrelaxed[i] = False\n",
    "        else:\n",
    "            hasrelaxed[i] = True\n",
    "\n",
    "    # Evaluate based on family\n",
    "    if family == 'A6--In--bct':\n",
    "        if np.isclose(c/a, 2**(0.5), atol=tol, rtol=0.0):\n",
    "            hasrelaxed[i] = True\n",
    "    elif family == 'L1_0--AuCu':\n",
    "        if np.isclose(c/a, 2**(0.5)/2, atol=tol, rtol=0.0):\n",
    "            hasrelaxed[i] = True\n",
    "            \n",
    "raw_df['hasrelaxed'] = hasrelaxed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Investigate important structures \n",
    "\n",
    "Look at the wanted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'C', u'E_cohesive', u'LAMMPS_version', u'calc_key', u'calc_script',\n",
       "       u'error', u'family', u'final_a', u'final_b', u'final_c', u'initial_a',\n",
       "       u'initial_b', u'initial_c', u'iprPy_version', u'load_file',\n",
       "       u'load_options', u'load_style', u'potential_LAMMPS_id',\n",
       "       u'potential_LAMMPS_key', u'potential_id', u'potential_key',\n",
       "       u'pressure_xx', u'pressure_yy', u'pressure_zz', u'sizemults', u'status',\n",
       "       u'strainrange', u'symbols', u'temperature', u'composition',\n",
       "       u'currentIPR', u'hasrelaxed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 fcc records\n",
      "52 bcc records\n"
     ]
    }
   ],
   "source": [
    "fcc_df = raw_df[(raw_df.family=='A1--Cu--fcc') & (raw_df.hasrelaxed==False)].reset_index()\n",
    "bcc_df = raw_df[(raw_df.family=='A2--W--bcc') & (raw_df.hasrelaxed==False)].reset_index()\n",
    "print(len(fcc_df), 'fcc records')\n",
    "print(len(bcc_df), 'bcc records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_cubic_properties(df):\n",
    "    df['a (Angstrom)'] = (df.final_a + df.final_b + df.final_c) / 3\n",
    "    c11s = []\n",
    "    c12s = []\n",
    "    c44s = []\n",
    "    for i, row in df.iterrows():\n",
    "        cij = row.C.Cij\n",
    "        c11 = (cij[0,0] + cij[1,1] + cij[2,2]) / 3\n",
    "        c12 = (cij[0,1] + cij[0,2] + cij[1,2]) / 3\n",
    "        c44 = (cij[3,3] + cij[4,4] + cij[5,5]) / 3\n",
    "\n",
    "        c11s.append(uc.get_in_units(c11, 'eV/Angstrom^3'))\n",
    "        c12s.append(uc.get_in_units(c12, 'eV/Angstrom^3'))\n",
    "        c44s.append(uc.get_in_units(c44, 'eV/Angstrom^3'))\n",
    "    df['C11 (eV/Angstrom^3)'] = c11s\n",
    "    df['C12 (eV/Angstrom^3)'] = c12s\n",
    "    df['C44 (eV/Angstrom^3)'] = c44s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_cubic_properties(fcc_df)\n",
    "add_cubic_properties(bcc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showkeys = ['potential_LAMMPS_id', 'composition', 'calc_script', \n",
    "            'E_cohesive', 'a (Angstrom)', 'C11 (eV/Angstrom^3)', 'C12 (eV/Angstrom^3)', 'C44 (eV/Angstrom^3)']\n",
    "sortkeys = ['potential_LAMMPS_id', 'composition', 'calc_script']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fcc_df[showkeys].sort_values(sortkeys).to_csv('fcc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcc_df[showkeys].sort_values(sortkeys).to_csv('bcc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
