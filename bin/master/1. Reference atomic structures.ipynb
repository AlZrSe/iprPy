{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference atomic structures\n",
    "\n",
    "This Notebook gets reference atomic crystal structures from various external sites and compares them to known crystal prototype structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Library imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iprPy version 0.8.a\n"
     ]
    }
   ],
   "source": [
    "# Standard Python libraries\n",
    "from __future__ import (print_function, division, absolute_import,\n",
    "                        unicode_literals)\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# http://www.numpy.org/\n",
    "import numpy as np\n",
    "\n",
    "# https://pandas.pydata.org/\n",
    "import pandas as pd\n",
    "\n",
    "# https://github.com/usnistgov/atomman\n",
    "import atomman as am\n",
    "import atomman.lammps as lmp\n",
    "\n",
    "# https://github.com/usnistgov/iprPy\n",
    "import iprPy\n",
    "print('iprPy version', iprPy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build unique sets of elements from included potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = iprPy.load_database(style='local', host='C:/Users/lmh1/Documents/calculations/ipr/reference_spacegroup')\n",
    "database.build_refs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all elements lists from potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_set = set()\n",
    "for potential_record in database.get_records(style='potential_LAMMPS'):\n",
    "    potential = lmp.Potential(potential_record.content)\n",
    "    elements = potential.elements()\n",
    "    elements.sort()\n",
    "    elements_set.add(' '.join(elements))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Materials Project reference structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define get_mp_structures() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mp_structures(elements, api_key=None, lib_directory=None):\n",
    "    \"\"\"\n",
    "    Accesses the Materials Project and downloads all structures for a list of\n",
    "    elements as poscar files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elements : list\n",
    "        A list of element symbols.\n",
    "    api_key : str, optional\n",
    "        The user's Materials Project API key. If not given, will use \"MAPI_KEY\"\n",
    "        environment variable\n",
    "    lib_directory : str\n",
    "        Path to the lib_directory to save the poscar files to.  Default uses\n",
    "        the iprPy library/dft_structures directory.\n",
    "    \"\"\"\n",
    "    # Function-specific imports\n",
    "    import pymatgen as pmg\n",
    "    from pymatgen.ext.matproj import MPRester\n",
    "    \n",
    "    # Define subset generator\n",
    "    def subsets(fullset):\n",
    "        for i, item in enumerate(fullset):\n",
    "            yield [item]\n",
    "            if len(fullset) > 1:\n",
    "                for subset in subsets(fullset[i+1:]):\n",
    "                    yield [item] + subset\n",
    "    \n",
    "    # Handle lib_directory\n",
    "    if lib_directory is None:\n",
    "        lib_directory = os.path.join(os.path.dirname(iprPy.rootdir), 'library', 'ref')\n",
    "    lib_directory = os.path.abspath(lib_directory)\n",
    "    \n",
    "    elements.sort()\n",
    "    \n",
    "    # Open connection to Materials Project\n",
    "    with MPRester(api_key) as m:\n",
    "        \n",
    "        # Loop over subsets of elements\n",
    "        for subelements in subsets(elements):\n",
    "            \n",
    "            # Set comp_directory\n",
    "            elements_string = '-'.join(subelements)\n",
    "            comp_directory = os.path.join(lib_directory, elements_string)\n",
    "            if not os.path.isdir(comp_directory):\n",
    "                os.makedirs(comp_directory)\n",
    "            \n",
    "            # Build list of downloaded entries\n",
    "            have = []\n",
    "            for fname in glob.iglob(os.path.join(comp_directory, 'mp-*.poscar')):\n",
    "                have.append(os.path.splitext(os.path.basename(fname))[0])\n",
    "            #print('Have', len(have), elements_string, 'records')\n",
    "            \n",
    "            # Query MP for all entries corresponding to the elements\n",
    "            entries = m.query({\"elements\": subelements}, [\"material_id\"])\n",
    "            \n",
    "            # Add entries to the list if not there\n",
    "            missing = []\n",
    "            for entry in entries:\n",
    "                if entry['material_id'] not in have and entry['material_id'] not in missing:\n",
    "                    missing.append(entry['material_id'])\n",
    "            #print('Missing', len(missing), elements_string, 'records')\n",
    "            \n",
    "            # Download missing entries\n",
    "            entries = m.query({\"material_id\": {\"$in\": missing}}, ['material_id', 'cif'])\n",
    "            \n",
    "            # Convert cif to poscar and save\n",
    "            for entry in entries:\n",
    "                struct = pmg.Structure.from_str(entry['cif'], fmt='cif')\n",
    "                struct = pmg.symmetry.analyzer.SpacegroupAnalyzer(struct).get_conventional_standard_structure()\n",
    "                system = am.load('pymatgen_Structure', struct)\n",
    "                system = system.normalize()\n",
    "                structure_file = os.path.join(comp_directory, entry['material_id']+'.poscar')\n",
    "                system.dump('poscar', f=structure_file)\n",
    "                print('Added', entry['material_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmh1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pymatgen\\io\\cif.py:44: UserWarning: Please install optional dependency pybtex if youwant to extract references from CIF files.\n",
      "  warnings.warn(\"Please install optional dependency pybtex if you\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added mvc-11115\n",
      "Added mvc-11423\n",
      "Added mvc-11500\n",
      "Added mvc-11600\n",
      "Added mvc-11912\n",
      "Added mvc-12404\n",
      "Added mvc-12466\n",
      "Added mvc-12939\n",
      "Added mvc-13391\n",
      "Added mvc-1923\n",
      "Added mvc-2169\n",
      "Added mvc-379\n",
      "Added mvc-4715\n",
      "Added mvc-5171\n",
      "Added mvc-6590\n",
      "Added mvc-9726\n",
      "Added mvc-388\n",
      "Added mvc-13894\n",
      "Added mvc-4415\n",
      "Added mvc-8453\n"
     ]
    }
   ],
   "source": [
    "mp_api_key_location = 'C:\\\\users\\\\lmh1\\\\Documents\\\\Materials Project\\\\API key.txt'\n",
    "\n",
    "with open(mp_api_key_location) as f:\n",
    "    mp_api_key = f.read()\n",
    "\n",
    "for elements in elements_set:\n",
    "    get_mp_structures(elements.split(), api_key=mp_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch OQMD reference structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define get_oqmd_structures() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oqmd_structures(elements, lib_directory=None):\n",
    "    \"\"\"\n",
    "    Accesses the Materials Project and downloads all structures for a list of\n",
    "    elements as poscar files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    elements : list\n",
    "        A list of element symbols.\n",
    "    lib_directory : str\n",
    "        Path to the lib_directory to save the poscar files to.  Default uses\n",
    "        the iprPy library/dft_structures directory.\n",
    "    \"\"\"\n",
    "    # Function-specific imports\n",
    "    import requests\n",
    "    \n",
    "    # Define subset generator\n",
    "    def subsets(fullset):\n",
    "        for i, item in enumerate(fullset):\n",
    "            yield [item]\n",
    "            if len(fullset) > 1:\n",
    "                for subset in subsets(fullset[i+1:]):\n",
    "                    yield [item] + subset\n",
    "    \n",
    "    # Get default lib_directory\n",
    "    if lib_directory is None:\n",
    "        lib_directory = os.path.join(os.path.dirname(iprPy.rootdir), 'library', 'ref')\n",
    "    lib_directory = os.path.abspath(lib_directory)\n",
    "    \n",
    "    # Set comp_directory\n",
    "    elements.sort()\n",
    "    have = []\n",
    "    for subelements in subsets(elements):\n",
    "        elements_string = '-'.join(subelements)\n",
    "        comp_directory = os.path.join(lib_directory, elements_string)\n",
    "        if not os.path.isdir(comp_directory):\n",
    "            os.makedirs(comp_directory)\n",
    "        \n",
    "        # Build list of downloaded entries\n",
    "        for fname in glob.iglob(os.path.join(comp_directory, 'oqmd-*.poscar')):\n",
    "            have.append(os.path.splitext(os.path.basename(fname))[0])\n",
    "    #print('Have', len(have), 'records')\n",
    "    \n",
    "    # Build list of missing OQMD entries\n",
    "    elements_string = '-'.join(elements)\n",
    "    \n",
    "    composition_r = requests.get('http://oqmd.org/materials/composition/' + elements_string)\n",
    "    composition_html = composition_r.text\n",
    "    \n",
    "    missing = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        try:\n",
    "            start = composition_html.index('href=\"/materials/entry/') + len('href=\"/materials/entry/')\n",
    "        except:\n",
    "            break\n",
    "        else:\n",
    "            end = start + composition_html[start:].index('\">')\n",
    "            entry_number = composition_html[start:end]\n",
    "            composition_html = composition_html[end+2:]\n",
    "            entry_id = 'oqmd-'+entry_number\n",
    "            if entry_id not in have and entry_id not in missing:\n",
    "                missing.append(entry_id)\n",
    "        if count > 100:\n",
    "            raise ValueError('Loop likely infinite')\n",
    "    #print('Missing', len(missing), 'records')\n",
    "    \n",
    "    # Download missing entries\n",
    "    for entry_id in missing:\n",
    "        entry_number = entry_id.replace('oqmd-', '')\n",
    "        entry_r = requests.get('http://oqmd.org/materials/entry/' + entry_number)\n",
    "        entry_html = entry_r.text\n",
    "        \n",
    "        start = entry_html.index('href=\"/materials/structure/') + len('href=\"/materials/structure/')\n",
    "        end = start + entry_html[start:].index('\">')\n",
    "        structure_number = entry_html[start:end]\n",
    "        \n",
    "        try:\n",
    "            structure_url = 'http://oqmd.org/materials/export/conventional/poscar/' + structure_number\n",
    "            structure_r = requests.get(structure_url)\n",
    "            structure_r.raise_for_status()\n",
    "        except:\n",
    "            try:\n",
    "                structure_url = 'http://oqmd.org/materials/export/primitive/poscar/' + structure_number\n",
    "                structure_r = requests.get(structure_url)\n",
    "                structure_r.raise_for_status()\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Save poscar\n",
    "        poscar = structure_r.text\n",
    "        system = am.load('poscar', poscar)\n",
    "        system = system.normalize()\n",
    "        elements_string = '-'.join(system.symbols)\n",
    "        structure_file = os.path.join(lib_directory, elements_string, entry_id + '.poscar')\n",
    "        \n",
    "        with open(structure_file, 'w') as f:\n",
    "            f.write(poscar)\n",
    "        print('Added', entry_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: Al Nb Ti\n",
      "Failed: Al Cu Fe Mg Si\n",
      "Failed: C H O\n",
      "Failed: C Fe Ti\n",
      "Failed: Cd Hg S Se Te Zn\n"
     ]
    }
   ],
   "source": [
    "for elements in elements_set:\n",
    "    try:\n",
    "        get_oqmd_structures(elements.split())\n",
    "    except:\n",
    "        print('Failed:', elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run crystal_space_group calculations on the reference structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In database style local at C:\\Users\\lmh1\\Documents\\calculations\\ipr\\reference_spacegroup :\n",
      "- 1704 of style calculation_crystal_space_group\n",
      " - 1685 are complete\n",
      " - 19 still to run\n",
      " - 0 issued errors\n"
     ]
    }
   ],
   "source": [
    "calculation = iprPy.load_calculation('crystal_space_group')\n",
    "run_directory = 'torun'\n",
    "\n",
    "input_dict = {}\n",
    "input_dict['buildcombos'] = ['crystalprototype load_file', \n",
    "                             'atomicreference load_file']\n",
    "\n",
    "database.prepare(run_directory, calculation, **input_dict)\n",
    "database.check_records(calculation.record_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner started with pid 12032\n",
      "No simulations left to run\n"
     ]
    }
   ],
   "source": [
    "database.runner(run_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In database style local at C:\\Users\\lmh1\\Documents\\calculations\\ipr\\reference_spacegroup :\n",
      "- 1704 of style calculation_crystal_space_group\n",
      " - 1704 are complete\n",
      " - 0 still to run\n",
      " - 0 issued errors\n"
     ]
    }
   ],
   "source": [
    "database.check_records(calculation.record_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Match prototypes to references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get results and split into reference and prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = database.get_records_df(style=calculation.record_style, full=True, flat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df = results_df[results_df.family+'.poscar'==results_df.load_file].reset_index()\n",
    "prototype_df = results_df[results_df.family+'.json'==results_df.load_file].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match based on space group information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    match_df = pd.read_csv('reference_prototype_match.csv')\n",
    "except:\n",
    "    match_df = pd.DataFrame()\n",
    "\n",
    "if len(reference_df) != len(match_df):\n",
    "    # Match based on Pearson symbol and space group number\n",
    "    match_df = []\n",
    "    for reference in reference_df.itertuples():\n",
    "        match_dict = {}\n",
    "        match_dict['reference'] = reference.family\n",
    "        match_dict['site'], match_dict['number'] = reference.family.split('-')\n",
    "        match_dict['number'] = int(match_dict['number'])\n",
    "        matches = prototype_df[((reference.pearson_symbol == prototype_df.pearson_symbol)\n",
    "                               &(reference.spacegroup_number == prototype_df.spacegroup_number))]\n",
    "        if len(matches) == 1:\n",
    "            match_dict['prototype'] = matches.iloc[0].family\n",
    "            match_dict['ref_wykoff'] = reference.wykoff_letters\n",
    "        elif len(matches) == 0:\n",
    "            match_dict['prototype'] = np.nan\n",
    "        else:\n",
    "            match_dict['prototype'] = 'multiple'\n",
    "        match_df.append(match_dict)\n",
    "    match_df = pd.DataFrame(match_df)\n",
    "\n",
    "    # Check known equivalent Wykoff sites for prototypes\n",
    "    match_df.loc[(match_df.prototype=='A1--Cu--fcc') & (~match_df.ref_wykoff.isin(['a', 'b'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A2--W--bcc') & (~match_df.ref_wykoff.isin(['a'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A3--Mg--hcp') & (~match_df.ref_wykoff.isin(['b', 'c', 'd'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype==\"A3'--alpha-La--double-hcp\") & (~match_df.ref_wykoff.isin(['a b', 'a c', 'a d'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A4--C--dc') & (~match_df.ref_wykoff.isin(['a', 'b'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A5--beta-Sn') & (~match_df.ref_wykoff.isin(['a', 'b'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A6--In--bct') & (~match_df.ref_wykoff.isin(['a', 'b'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A7--alpha-As') & (~match_df.ref_wykoff.isin(['c'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='Ah--alpha-Po--sc') & (~match_df.ref_wykoff.isin(['a', 'b'])),\n",
    "                 'prototype'] = np.nan\n",
    "    match_df.loc[(match_df.prototype=='A15--beta-W') & (~match_df.ref_wykoff.isin(['a c', 'a d'])),\n",
    "                 'prototype'] = np.nan\n",
    "\n",
    "    match_df = match_df.sort_values(['site', 'number']).reset_index()[['reference', 'prototype']]\n",
    "    match_df.to_csv('reference_prototype_match.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
